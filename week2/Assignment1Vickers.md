# Assignment 1: Git and GitHub Setup

## Overview
This assignment covers Git version control research, GitHub repository setup, and advanced exercises on AI ethics and technical limitations.

---

## Activities Completed

### Activity 1: Research Git
- **Documentation**: [Activity 1: Research Git](Week2Activiy1.md)
- **Coverage**: Comprehensive overview of Git architecture, version control systems, and core concepts

### Activity 2: Setting up a New GitHub and Local Repository
- **Repository**: [MSSE640-2025summer GitHub Repository](https://github.com/ThomasVickers-Regis/MSSE640-2025summer)
- **Setup**: Local repository configuration and GitHub integration

### Activity 3: Edit the README.md File and Push to GitHub Repository
- **Documentation**: [GitHub README](../README.md)
- **Implementation**: Updated project documentation and pushed changes to remote repository

---

## Advanced Exercises

### Background Reading
For those who completed this project in a previous class, please read one or more of the following articles. Your response will reference one or two of these articles based on the question you select:

#### Required Articles:
1. **[ChatGPT Is a Blurry JPEG of the Web](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web)** - Ted Chiang
2. **[Challenging the Myths of Generative AI](https://www.noemamag.com/challenging-the-myths-of-generative-ai/)** - Noema Magazine
3. **[On the Dangers of Stochastic Parrots](https://dl.acm.org/doi/10.1145/3442188.3445922)** - Bender et al.
4. **[Why AI Can't Spell 'Strawberry'](https://www.nytimes.com/2023/12/19/technology/ai-spelling-strawberry.html)** - The New York Times

---

### Question Selection
Choose **one** of the following questions that interests you most. Base your response on the referenced articles.

---

#### Question 1: Environmental and Social Responsibilities
**What responsibilities do software engineers have in mitigating the environmental and social impacts of large language models (LLMs)?**

**References**: "On the Dangers of Stochastic Parrots" and "Challenging the Myths of Generative AI"

**Discussion Points**:
- Discuss the trade-offs between model size, performance, and environmental cost
- Should engineers prioritize technical excellence over equity and sustainability?
- Consider the carbon footprint of training and deploying large AI models
- Examine the social implications of AI bias and misinformation

---

#### Question 2: AI Myths and Public Perception
**How do myths and metaphors about AI (e.g., "learning," "creativity," "productivity") influence public perception and policy?**

**Reference**: "Challenging the Myths of Generative AI"

**Discussion Points**:
- Explore how language shapes beliefs about AI's capabilities and limitations
- How can software engineers and educators challenge misleading narratives?
- Analyze the impact of AI terminology on public understanding
- Consider the role of media and marketing in AI perception

---

#### Question 3: Blurry JPEG Risks
**If ChatGPT is a "blurry JPEG of the Web," what are the risks of using such tools in academic, journalistic, or legal settings?**

**Reference**: "ChatGPT Is a Blurry JPEG of the Web"

**Discussion Points**:
- Evaluate the implications of lossy AI-generated content
- How do accuracy, originality, and accountability suffer or thrive in such systems?
- Consider the reliability of AI-generated information in critical contexts
- Examine the potential for misinformation and hallucination

---

#### Question 4: Technical Limitations of LLMs
**What does the inability of LLMs to spell "strawberry" reveal about the architecture of current AI systems?**

**Reference**: "Why AI Can't Spell 'Strawberry'"

**Discussion Points**:
- Analyze the technical limitations of transformer-based models with respect to fine-grained symbolic understanding
- How might future designs address this gap?
- Consider the relationship between training data and model capabilities
- Examine the fundamental differences between human and AI learning

---

#### Question 5: Model Size and Effectiveness
**Are larger AI models inherently better? When might smaller, curated models be preferable in software engineering practice?**

**References**: "On the Dangers of Stochastic Parrots" and "Challenging the Myths of Generative AI"

**Discussion Points**:
- Debate the scaling myth and consider real-world scenarios
- When might model size not correlate with usefulness or trustworthiness?
- Consider edge devices, local AI, and resource-constrained environments
- Examine the trade-offs between accessibility and performance

---

## Response Guidelines

### Format Requirements:
- **Length**: 500-800 words
- **Structure**: Clear introduction, body paragraphs, and conclusion
- **Citations**: Properly reference the selected articles
- **Style**: Professional, academic tone

### Content Expectations:
- Demonstrate understanding of the selected articles
- Provide thoughtful analysis of the chosen question
- Include relevant examples and evidence
- Consider multiple perspectives on the issue
- Connect to software engineering practices and responsibilities

### Submission:
- Include your response below this section
- Clearly indicate which question you selected
- Provide proper citations and references
- Submit through the designated course platform

---

## My Response

*[Your response to the selected question will be added here]*

**Selected Question**: [Indicate which question you chose]

**Response**:

[Your 500-800 word response goes here]

---

## References

1. Chiang, T. (2023). ChatGPT Is a Blurry JPEG of the Web. *The New Yorker*.
2. Noema Magazine. (2023). Challenging the Myths of Generative AI.
3. Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? *Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency*.
4. The New York Times. (2023). Why AI Can't Spell 'Strawberry'.
